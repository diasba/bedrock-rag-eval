{"question": "What is Amazon Bedrock?", "ground_truth_answer": "Amazon Bedrock is a fully managed service that makes foundation models from leading AI companies available through a unified API.", "ground_truth_context": "Amazon Bedrock is a fully managed service that makes foundation models (FMs) from leading AI startups and Amazon available via an API.", "category": "factual"}
{"question": "Do you need model access permissions before using some Bedrock models?", "ground_truth_answer": "Yes, you need to request and be granted model access before you can use foundation models in Amazon Bedrock.", "ground_truth_context": "Before you can use a foundation model in Amazon Bedrock, you must request access to it.", "category": "factual"}
{"question": "Where can you find supported models for Bedrock?", "ground_truth_answer": "You can find the list of supported models in the Amazon Bedrock documentation under the supported models page.", "ground_truth_context": "For a list of models supported by Amazon Bedrock and the features they support, see Supported foundation models in Amazon Bedrock.", "category": "factual"}
{"question": "What is a Bedrock Knowledge Base used for?", "ground_truth_answer": "A Bedrock Knowledge Base is used to give foundation models contextual information from your private data sources for Retrieval Augmented Generation (RAG).", "ground_truth_context": "With knowledge bases, you can give foundation models and agents contextual information from your company's private data sources for Retrieval Augmented Generation (RAG).", "category": "factual"}
{"question": "What does chunking do in a knowledge base pipeline?", "ground_truth_answer": "Chunking splits documents into smaller segments so they can be efficiently embedded and retrieved during a query.", "ground_truth_context": "Chunking refers to the process of splitting your source documents into discrete segments (chunks) before they are embedded and stored in a vector index.", "category": "factual"}
{"question": "What is the purpose of RetrieveAndGenerate?", "ground_truth_answer": "RetrieveAndGenerate queries a knowledge base, retrieves relevant results, and generates a response by augmenting the foundation model prompt with the retrieved information.", "ground_truth_context": "RetrieveAndGenerate queries a knowledge base and generates responses based on the retrieved results, augmenting the foundation model prompt with context from the search results.", "category": "factual"}
{"question": "What two types of RAG evaluation jobs can you set up in Amazon Bedrock evaluations?", "ground_truth_answer": "You can set up two types of jobs: retrieve-only and retrieve-and-generate.", "ground_truth_context": "You can set up two different types of RAG evaluation jobs. Retrieve only - In a retrieve-only RAG evaluation job, the report is based on the data retrieved from your RAG source. Retrieve and generate - In a retrieve-and-generate RAG evaluation job, the report is based on the data retrieved from your knowledge base and the summaries generated by the response generator model.", "category": "factual"}
{"question": "What does contextual grounding check in Bedrock Guardrails evaluate?", "ground_truth_answer": "It evaluates grounding and relevance of a model response against the provided source and user query.", "ground_truth_context": "Contextual grounding checks the following paradigms: Grounding - checks if the model response is factually accurate based on the source and is grounded in the source. Relevance - checks if the model response is relevant to the user query.", "category": "factual"}
{"question": "How do model access and supported regions together affect deployment planning in Bedrock?", "ground_truth_answer": "Deployment planning requires checking both model access permissions (which must be requested per model) and supported regions (since not all models are available in all AWS regions), so teams must confirm regional availability before requesting access.", "ground_truth_context": "Before you can use a foundation model in Amazon Bedrock, you must request access to it. Not all models are available in every AWS Region. For a list of Regions that support each model, see Supported models by Region.", "category": "multi_hop"}
{"question": "Why are chunking settings and retrieval configuration both important for answer quality?", "ground_truth_answer": "Chunking controls the granularity of document segments stored in the vector index, while retrieval configuration controls how many chunks are returned and how they are ranked. Together they determine whether the right information at the right level of detail reaches the LLM for generation.", "ground_truth_context": "Chunking refers to the process of splitting your source documents into discrete segments (chunks) before they are embedded and stored in a vector index. You can configure the maximum number of retrieved results and a minimum confidence threshold for filtering results.", "category": "multi_hop"}
{"question": "How are Knowledge Bases and guardrails complementary in a production assistant?", "ground_truth_answer": "Knowledge Bases provide the RAG capability to ground answers in private data, while guardrails add safety layers like content filtering and sensitive information masking. Together they enable an assistant that is both accurate and safe.", "ground_truth_context": "With knowledge bases, you can give foundation models contextual information from your company's private data sources for RAG. Guardrails for Amazon Bedrock evaluates user inputs and model responses based on use-case-specific policies, including content filters and sensitive information filters.", "category": "multi_hop"}
{"question": "How do quotas and endpoints influence runtime behavior for inference calls?", "ground_truth_answer": "Quotas define the maximum request rate and token limits per model per region. Endpoints determine the network path for API calls. Together, exceeding quotas at a given endpoint leads to throttling (InvocationThrottles), and choosing the right endpoint-region pair is necessary to get sufficient throughput.", "ground_truth_context": "Amazon Bedrock has quotas for the maximum number of API requests per second per model per Region. The InvocationThrottles metric reports the number of invocations that the system throttled. The number of throttles depends on retry settings in the SDK.", "category": "multi_hop"}
{"question": "Can Bedrock KB do RAG-style retrieval before generation?", "ground_truth_answer": "Yes, Bedrock Knowledge Bases support RAG-style retrieval before generation through the RetrieveAndGenerate API, which first queries the knowledge base for relevant results and then uses them to augment the prompt for the foundation model.", "ground_truth_context": "RetrieveAndGenerate queries a knowledge base and generates responses based on the retrieved results, augmenting the foundation model prompt with context from the search results.", "category": "paraphrase"}
{"question": "How do I check token count before sending a prompt?", "ground_truth_answer": "You can use the CountTokens API operation to count the number of tokens in a prompt before sending it to a model.", "ground_truth_context": "Use the CountTokens API to count the number of tokens in a text string or prompt before sending it to a model for inference.", "category": "paraphrase"}
{"question": "Is there an API for streaming model responses?", "ground_truth_answer": "Yes, Amazon Bedrock supports response streaming through the InvokeModelWithResponseStream and ConverseStream API operations. The field 'responseStreamingSupported' in the API documentation indicates whether a specific model supports streaming.", "ground_truth_context": "Some Amazon Bedrock Runtime API operations support response streaming. In the API documentation, the field 'responseStreamingSupported' indicates whether a specific model supports response streaming. Relevant operations for streaming include: ConverseStream, InvokeModelWithResponseStream.", "category": "paraphrase"}
{"question": "Can I directly apply a guardrail through an API call?", "ground_truth_answer": "Yes, you can apply a guardrail directly through the ApplyGuardrail API operation, which evaluates content against your configured guardrail policies.", "ground_truth_context": "The ApplyGuardrail API sends a request to apply a guardrail, evaluating the provided content against the policies configured in the specified guardrail.", "category": "paraphrase"}
{"question": "What are the runtime metrics Amazon Bedrock tracks for model invocations?", "ground_truth_answer": "Amazon Bedrock tracks Invocations, InvocationLatency, InvocationClientErrors, InvocationServerErrors, InvocationThrottles, InputTokenCount, OutputTokenCount, LegacyModelInvocations, and OutputImageCount.", "ground_truth_context": "The following table describes runtime metrics provided by Amazon Bedrock: Invocations, InvocationLatency, InvocationClientErrors, InvocationServerErrors, InvocationThrottles, InputTokenCount, LegacyModelInvocations, OutputTokenCount, OutputImageCount.", "category": "paraphrase"}
{"question": "Does Bedrock support tag-based access control for its resources?", "ground_truth_answer": "Yes, Amazon Bedrock supports attribute-based access control (ABAC) using tags, with condition keys like aws:ResourceTag, aws:RequestTag, and aws:TagKeys.", "ground_truth_context": "Amazon Bedrock supports ABAC with service-specific tags on Bedrock resources. You can use the aws:ResourceTag, aws:RequestTag, and aws:TagKeys condition keys.", "category": "paraphrase"}
{"question": "What is the default PostgreSQL version used internally by Bedrock?", "ground_truth_answer": null, "ground_truth_context": "", "category": "no_answer"}
{"question": "Which color theme does the AWS Bedrock console use by default?", "ground_truth_answer": null, "ground_truth_context": "", "category": "no_answer"}
{"question": "What salary does an AWS Bedrock product manager earn?", "ground_truth_answer": null, "ground_truth_context": "", "category": "no_answer"}
{"question": "What was the weather in Seattle when Bedrock launched?", "ground_truth_answer": null, "ground_truth_context": "", "category": "no_answer"}
