{
  "judge_mode": true,
  "llm_enabled": true,
  "llm_status": "Mistral API operational (model: mistral-large-latest)",
  "metrics_source": "judge",
  "chroma_stats": {
    "total_chunks": 953,
    "by_content_type": {
      "md": 914,
      "pdf": 32,
      "txt": 7
    },
    "top_docs": [
      {
        "doc_id": "md/kb-test-config.html-9197bf87.md",
        "chunks": 90
      },
      {
        "doc_id": "md/api_runtime_converse.html-40f9e6b4.md",
        "chunks": 64
      },
      {
        "doc_id": "md/models-supported.html-fd18f626.md",
        "chunks": 60
      },
      {
        "doc_id": "md/api_runtime_conversestream.html-9e1a37d7.md",
        "chunks": 59
      },
      {
        "doc_id": "md/model-access.html-2e8fa3aa.md",
        "chunks": 57
      }
    ],
    "md_count": 914
  },
  "aggregate": {
    "context_precision": 0.6556,
    "context_recall": 0.775,
    "faithfulness": 0.8083,
    "answer_relevancy": 0.5941,
    "answer_correctness": 0.73
  },
  "per_question": [
    {
      "question": "What is Amazon Bedrock?",
      "category": "factual",
      "predicted_answer": "Amazon Bedrock is a fully managed service that provides secure, enterprise-grade access to high-performing foundation models from leading AI companies to build and scale generative AI applications [Chunk 1].",
      "ground_truth_answer": "Amazon Bedrock is a fully managed service that makes foundation models from leading AI companies available through a unified API.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 1.0,
      "answer_correctness": 0.7522
    },
    {
      "question": "Do you need model access permissions before using some Bedrock models?",
      "category": "factual",
      "predicted_answer": "Yes, you need permissions for `bedrock:InvokeModel` or `bedrock:InvokeModelWithResponseStream` actions to use Bedrock models, and access to third-party models requires programmatic access management [Chunk 1][Chunk 2][Chunk 3][Chunk 4].",
      "ground_truth_answer": "Yes, you need to request and be granted model access before you can use foundation models in Amazon Bedrock.",
      "context_precision": 0.6389,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.9002,
      "answer_correctness": 0.468
    },
    {
      "question": "Where can you find supported models for Bedrock?",
      "category": "factual",
      "predicted_answer": "Supported models for Amazon Bedrock are listed in the table under \"Supported foundation models in Amazon Bedrock\" in the documentation [Chunk 1]. You can also find supported embedding models for knowledge bases in \"Supported models and Regions for Amazon Bedrock knowledge bases\" [Chunk 2].",
      "ground_truth_answer": "You can find the list of supported models in the Amazon Bedrock documentation under the supported models page.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.8729,
      "answer_correctness": 0.6559
    },
    {
      "question": "What is a Bedrock Knowledge Base used for?",
      "category": "factual",
      "predicted_answer": "A Bedrock Knowledge Base is used to integrate proprietary information into generative-AI applications via Retrieval Augmented Generation (RAG), improving response relevancy and accuracy by retrieving relevant data from connected data sources [Chunk 1][Chunk 4].",
      "ground_truth_answer": "A Bedrock Knowledge Base is used to give foundation models contextual information from your private data sources for Retrieval Augmented Generation (RAG).",
      "context_precision": 0.75,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 1.0,
      "answer_correctness": 0.7273
    },
    {
      "question": "What does chunking do in a knowledge base pipeline?",
      "category": "factual",
      "predicted_answer": "Chunking splits each document in a data source into smaller subdivisions (chunks) based on token count, overlap tokens, or semantic content to improve retrieval accuracy [Chunk 1][Chunk 4].",
      "ground_truth_answer": "Chunking splits documents into smaller segments so they can be efficiently embedded and retrieved during a query.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.6639,
      "answer_correctness": 0.5805
    },
    {
      "question": "What is the purpose of RetrieveAndGenerate?",
      "category": "factual",
      "predicted_answer": "The `RetrieveAndGenerate` operation combines query conversion (via `GenerateQuery` for structured data), retrieval, and model invocation to perform the full RAG process in Amazon Bedrock Knowledge Bases [Chunk 1].",
      "ground_truth_answer": "RetrieveAndGenerate queries a knowledge base, retrieves relevant results, and generates a response by augmenting the foundation model prompt with the retrieved information.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.6357,
      "answer_correctness": 0.5675
    },
    {
      "question": "What is enabled by default with the correct AWS Marketplace permissions, and which table shows model support by AWS Region?",
      "category": "multi_hop",
      "predicted_answer": "Access to all Amazon Bedrock foundation models is enabled by default with the correct AWS Marketplace permissions [Chunk 1]. The table showing model support by AWS Region is found in the \"Models and Regions\" documentation [Chunk 2].",
      "ground_truth_answer": "Access to all Amazon Bedrock foundation models is enabled by default with the correct AWS Marketplace permissions. Model support by AWS Region is shown in the model support by AWS Region table.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 0.5,
      "answer_relevancy": 0.4708,
      "answer_correctness": 0.7852
    },
    {
      "question": "In fixed-size chunking, what two settings define chunk size and overlap, and in retrievalConfiguration.vectorSearchConfiguration which field sets the maximum number of results?",
      "category": "multi_hop",
      "predicted_answer": "In fixed-size chunking, the two settings are the **maximum number of tokens per chunk** and the **overlap percentage** [Chunk 2]. In `retrievalConfiguration.vectorSearchConfiguration`, the **`numberOfResults`** field sets the maximum number of results [Chunk 1].",
      "ground_truth_answer": "In fixed-size chunking, the two settings are the number of tokens per chunk and the overlap percentage. In retrievalConfiguration.vectorSearchConfiguration, the field that sets the maximum number of results is numberOfResults.",
      "context_precision": 0.5,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.8279,
      "answer_correctness": 0.7667
    },
    {
      "question": "In Amazon Bedrock, which feature searches your data to answer a query, and which feature evaluates both user inputs and model responses?",
      "category": "multi_hop",
      "predicted_answer": "Amazon Bedrock Knowledge Bases search your data to answer a query [Chunk 1], while Bedrock Guardrails evaluate both user inputs (prompts) and model responses [Chunk 2].",
      "ground_truth_answer": "When a query is made, a knowledge base searches your data to find relevant information to answer the query. Amazon Bedrock Guardrails evaluates both user inputs and model responses.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.4362,
      "answer_correctness": 0.7471
    },
    {
      "question": "For Amazon Bedrock inference, which endpoint is used for InvokeModel calls, and what controls model inference usage?",
      "category": "multi_hop",
      "predicted_answer": "Use the region-specific endpoint `bedrock-runtime.{region}.amazonaws.com` for InvokeModel calls [Chunk 1]. Model inference usage is controlled via inference parameters [Chunk 2] and access to service tiers [Chunk 3].",
      "ground_truth_answer": "InvokeModel calls use the bedrock-runtime.{region}.amazonaws.com endpoint. Model inference in Amazon Bedrock is controlled by quotas on token usage.",
      "context_precision": 1.0,
      "context_recall": 0.5,
      "faithfulness": 0.6667,
      "answer_relevancy": 0.7689,
      "answer_correctness": 0.6953
    },
    {
      "question": "Can Bedrock KB do RAG-style retrieval before generation?",
      "category": "paraphrase",
      "predicted_answer": "Yes, Amazon Bedrock Knowledge Bases supports RAG-style retrieval before generation using the **Retrieve** and **RetrieveAndGenerate** operations [Chunk 3][Chunk 4].",
      "ground_truth_answer": "Yes, Bedrock Knowledge Bases support RAG-style retrieval before generation through the RetrieveAndGenerate API, which first queries the knowledge base for relevant results and then uses them to augment the prompt for the foundation model.",
      "context_precision": 0.8056,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.7292,
      "answer_correctness": 0.7042
    },
    {
      "question": "How do I check token count before sending a prompt?",
      "category": "paraphrase",
      "predicted_answer": "Use the `CountTokens` operation, which accepts the same input formats as `InvokeModel` or `Converse` [Chunk 1].",
      "ground_truth_answer": "You can use the CountTokens API operation to count the number of tokens in a prompt before sending it to a model.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.5711,
      "answer_correctness": 0.4044
    },
    {
      "question": "Is there an API for streaming model responses?",
      "category": "paraphrase",
      "predicted_answer": "Yes, the supported streaming APIs are **ConverseStream** and **InvokeModelWithResponseStream** [Chunk 4]. For knowledge bases, use **RetrieveAndGenerateStream** [Chunk 1].",
      "ground_truth_answer": "Yes, Amazon Bedrock supports response streaming through the InvokeModelWithResponseStream and ConverseStream API operations. The field 'responseStreamingSupported' in the API documentation indicates whether a specific model supports streaming.",
      "context_precision": 0.4167,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.6453,
      "answer_correctness": 0.65
    },
    {
      "question": "Can I directly apply a guardrail through an API call?",
      "category": "paraphrase",
      "predicted_answer": "Yes, you can directly apply a guardrail through the **ApplyGuardrail API** without invoking a foundation model [Chunk 1][Chunk 4].",
      "ground_truth_answer": "Yes, you can apply a guardrail directly through the ApplyGuardrail API operation, which evaluates content against your configured guardrail policies.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.7878,
      "answer_correctness": 0.7216
    },
    {
      "question": "Name at least 5 runtime invocation metrics Bedrock publishes (CloudWatch)",
      "category": "paraphrase",
      "predicted_answer": "Amazon Bedrock publishes these runtime invocation metrics: Invocations, InvocationLatency, InvocationClientErrors, InvocationServerErrors, InvocationThrottles, InputTokenCount, OutputTokenCount [Chunk 1][Chunk 2][Chunk 4].",
      "ground_truth_answer": "Amazon Bedrock tracks Invocations, InvocationLatency, InvocationClientErrors, InvocationServerErrors, InvocationThrottles, InputTokenCount, OutputTokenCount, LegacyModelInvocations, and OutputImageCount.",
      "context_precision": 0.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.7957,
      "answer_correctness": 0.654
    },
    {
      "question": "In Amazon Bedrock inference, which service tier is used by default when the 'service_tier' parameter is missing?",
      "category": "factual",
      "predicted_answer": "The Standard tier is used by default when the \"service_tier\" parameter is missing [Chunk 1][Chunk 2].",
      "ground_truth_answer": "By default, inference requests are routed to the Standard tier when the 'service_tier' parameter is missing.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.7763,
      "answer_correctness": 0.7207
    },
    {
      "question": "What is the default PostgreSQL version used internally by Bedrock?",
      "category": "no_answer",
      "predicted_answer": null,
      "ground_truth_answer": null,
      "context_precision": 0.0,
      "context_recall": 0.0,
      "faithfulness": 0.0,
      "answer_relevancy": 0.0,
      "answer_correctness": 1.0
    },
    {
      "question": "Which color theme does the AWS Bedrock console use by default?",
      "category": "no_answer",
      "predicted_answer": null,
      "ground_truth_answer": null,
      "context_precision": 0.0,
      "context_recall": 0.0,
      "faithfulness": 0.0,
      "answer_relevancy": 0.0,
      "answer_correctness": 1.0
    },
    {
      "question": "What salary does an AWS Bedrock product manager earn?",
      "category": "no_answer",
      "predicted_answer": null,
      "ground_truth_answer": null,
      "context_precision": 0.0,
      "context_recall": 0.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.0,
      "answer_correctness": 1.0
    },
    {
      "question": "What was the weather in Seattle when Bedrock launched?",
      "category": "no_answer",
      "predicted_answer": null,
      "ground_truth_answer": null,
      "context_precision": 0.0,
      "context_recall": 0.0,
      "faithfulness": 0.0,
      "answer_relevancy": 0.0,
      "answer_correctness": 1.0
    }
  ]
}