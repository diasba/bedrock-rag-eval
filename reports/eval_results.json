{
  "judge_mode": true,
  "llm_enabled": true,
  "llm_status": "Mistral API operational (model: mistral-large-latest)",
  "metrics_source": "judge",
  "chroma_stats": {
    "total_chunks": 957,
    "by_content_type": {
      "md": 918,
      "pdf": 32,
      "txt": 7
    },
    "top_docs": [
      {
        "doc_id": "md/kb-test-config.html-9197bf87.md",
        "chunks": 90
      },
      {
        "doc_id": "md/api_runtime_converse.html-40f9e6b4.md",
        "chunks": 64
      },
      {
        "doc_id": "md/model-access.html-2e8fa3aa.md",
        "chunks": 60
      },
      {
        "doc_id": "md/models-supported.html-fd18f626.md",
        "chunks": 60
      },
      {
        "doc_id": "md/api_runtime_conversestream.html-9e1a37d7.md",
        "chunks": 59
      }
    ],
    "md_count": 918
  },
  "aggregate": {
    "context_precision": 0.4417,
    "context_recall": 0.6278,
    "faithfulness": 0.8754,
    "answer_relevancy": 0.6042,
    "answer_correctness": 0.7086
  },
  "per_question": [
    {
      "question": "What is Amazon Bedrock?",
      "category": "factual",
      "predicted_answer": "Amazon Bedrock is a service that provides access to supported foundation models from various providers for building generative AI applications [Chunk 1]. It also offers features like Knowledge Bases, which enable Retrieval Augmented Generation (RAG) to augment model responses with information from data stores [Chunk 2].",
      "ground_truth_answer": "Amazon Bedrock is a fully managed service that makes foundation models from leading AI companies available through a unified API.",
      "context_precision": 0.0,
      "context_recall": 0.0,
      "faithfulness": 0.8,
      "answer_relevancy": 0.9289,
      "answer_correctness": 0.4556
    },
    {
      "question": "Do you need model access permissions before using some Bedrock models?",
      "category": "factual",
      "predicted_answer": "Yes, you need model access permissions before using third-party models in Amazon Bedrock, as programmatic access requires explicit permission requests [Chunk 1]. However, access to all Amazon Bedrock foundation models is enabled by default with the correct AWS Marketplace permissions [Chunk 1].",
      "ground_truth_answer": "Yes, you need to request and be granted model access before you can use foundation models in Amazon Bedrock.",
      "context_precision": 0.5833,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.7514,
      "answer_correctness": 0.7038
    },
    {
      "question": "Where can you find supported models for Bedrock?",
      "category": "factual",
      "predicted_answer": "You can find the list of supported foundation models for Amazon Bedrock in the \"Supported foundation models in Amazon Bedrock\" section of the documentation [Chunk 1]. For embedding models specifically used in Bedrock knowledge bases, refer to \"Supported models and Regions for Amazon Bedrock knowledge bases\" [Chunk 2][Chunk 4].",
      "ground_truth_answer": "You can find the list of supported models in the Amazon Bedrock documentation under the supported models page.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.8235,
      "answer_correctness": 0.6583
    },
    {
      "question": "What is a Bedrock Knowledge Base used for?",
      "category": "factual",
      "predicted_answer": "A Bedrock Knowledge Base is used to connect to a data source and retrieve data or information when queried, enabling retrieval-augmented generation (RAG) workflows with large language models (LLMs) [Chunk 3, Chunk 4]. It allows you to define and identify a knowledge base, then query it to fetch relevant references, though guardrails are not applied to the retrieved data [Chunk 2, Chunk 3].",
      "ground_truth_answer": "A Bedrock Knowledge Base is used to give foundation models contextual information from your private data sources for Retrieval Augmented Generation (RAG).",
      "context_precision": 0.0,
      "context_recall": 0.0,
      "faithfulness": 0.8333,
      "answer_relevancy": 1.0,
      "answer_correctness": 0.6014
    },
    {
      "question": "What does chunking do in a knowledge base pipeline?",
      "category": "factual",
      "predicted_answer": "Chunking in a knowledge base pipeline splits documents or content into smaller, manageable segments during ingestion. These chunks are converted into embeddings and stored in a vector index to enable efficient data retrieval, while maintaining a link to the original document [Chunk 4]. This process helps shorten the content filled in the `$search_results$` placeholder in prompt templates, improving retrieval and generation performance [Chunk 1][Chunk 2].",
      "ground_truth_answer": "Chunking splits documents into smaller segments so they can be efficiently embedded and retrieved during a query.",
      "context_precision": 0.25,
      "context_recall": 1.0,
      "faithfulness": 0.875,
      "answer_relevancy": 0.9442,
      "answer_correctness": 0.6572
    },
    {
      "question": "What is the purpose of RetrieveAndGenerate?",
      "category": "factual",
      "predicted_answer": "The **RetrieveAndGenerate** operation combines the entire RAG (Retrieval-Augmented Generation) process by:\n1. Converting natural language queries into structured queries (if using a structured data store) via **GenerateQuery**,\n2. Retrieving relevant chunks from the knowledge base via **Retrieve**, and\n3. Generating a response using an LLM via **InvokeModel**, with citations to the original source data [Chunk 3][Chunk 4].",
      "ground_truth_answer": "RetrieveAndGenerate queries a knowledge base, retrieves relevant results, and generates a response by augmenting the foundation model prompt with the retrieved information.",
      "context_precision": 0.4167,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.6818,
      "answer_correctness": 0.5847
    },
    {
      "question": "What is enabled by default with the correct AWS Marketplace permissions, and which table shows model support by AWS Region?",
      "category": "multi_hop",
      "predicted_answer": "Access to all Amazon Bedrock foundation models is enabled by default with the correct AWS Marketplace permissions [Chunk 1]. The table showing inference profile support by AWS Region is found in the \"Supported Regions and models for inference profiles\" section [Chunk 2].",
      "ground_truth_answer": "Access to all Amazon Bedrock foundation models is enabled by default with the correct AWS Marketplace permissions. Model support by AWS Region is shown in the model support by AWS Region table.",
      "context_precision": 0.0,
      "context_recall": 0.5,
      "faithfulness": 1.0,
      "answer_relevancy": 0.4708,
      "answer_correctness": 0.7667
    },
    {
      "question": "In fixed-size chunking, what two settings define chunk size and overlap, and in retrievalConfiguration.vectorSearchConfiguration which field sets the maximum number of results?",
      "category": "multi_hop",
      "predicted_answer": "In fixed-size chunking, the two settings are the **maximum number of tokens per chunk** and the **overlap percentage** between consecutive chunks [Chunk 4]. In `retrievalConfiguration.vectorSearchConfiguration`, the field that sets the maximum number of results is **`numberOfResults`** [Chunk 1].",
      "ground_truth_answer": "In fixed-size chunking, the two settings are the number of tokens per chunk and the overlap percentage. In retrievalConfiguration.vectorSearchConfiguration, the field that sets the maximum number of results is numberOfResults.",
      "context_precision": 0.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.949,
      "answer_correctness": 0.7698
    },
    {
      "question": "In Amazon Bedrock, which feature searches your data to answer a query, and which feature evaluates both user inputs and model responses?",
      "category": "multi_hop",
      "predicted_answer": "The feature that searches your data to answer a query is **Amazon Bedrock Knowledge Bases** [Chunk 1]. The feature that evaluates both user inputs (prompts) and model responses is **Bedrock Guardrails** [Chunk 4].",
      "ground_truth_answer": "When a query is made, a knowledge base searches your data to find relevant information to answer the query. Amazon Bedrock Guardrails evaluates both user inputs and model responses.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.9068,
      "answer_correctness": 0.7546
    },
    {
      "question": "For Amazon Bedrock inference, which endpoint is used for InvokeModel calls, and what controls model inference usage?",
      "category": "multi_hop",
      "predicted_answer": "For InvokeModel calls in Amazon Bedrock, use the **region-specific endpoints** in the format `bedrock-runtime.{region}.amazonaws.com` [Chunk 1].\n\nModel inference usage is controlled through **Service Control Policies (SCP) or IAM policies**, which initially block access until you review and agree to the EULA terms [Chunk 3].",
      "ground_truth_answer": "InvokeModel calls use the bedrock-runtime.{region}.amazonaws.com endpoint. Model inference in Amazon Bedrock is controlled by quotas on token usage.",
      "context_precision": 1.0,
      "context_recall": 0.5,
      "faithfulness": 1.0,
      "answer_relevancy": 0.8622,
      "answer_correctness": 0.6112
    },
    {
      "question": "Can Bedrock KB do RAG-style retrieval before generation?",
      "category": "paraphrase",
      "predicted_answer": "Yes, Amazon Bedrock Knowledge Bases use Retrieval Augmented Generation (RAG) to retrieve relevant information from data sources before generating responses [Chunk 2][Chunk 3][Chunk 4].",
      "ground_truth_answer": "Yes, Bedrock Knowledge Bases support RAG-style retrieval before generation through the RetrieveAndGenerate API, which first queries the knowledge base for relevant results and then uses them to augment the prompt for the foundation model.",
      "context_precision": 0.5833,
      "context_recall": 0.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.6298,
      "answer_correctness": 0.6099
    },
    {
      "question": "How do I check token count before sending a prompt?",
      "category": "paraphrase",
      "predicted_answer": "Use the `CountTokens` API operation, which accepts the same input formats as `InvokeModel` or `Converse` and returns the token count that would be used for the given input [Chunk 1][Chunk 2].",
      "ground_truth_answer": "You can use the CountTokens API operation to count the number of tokens in a prompt before sending it to a model.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.5789,
      "answer_correctness": 0.5685
    },
    {
      "question": "Is there an API for streaming model responses?",
      "category": "paraphrase",
      "predicted_answer": "Yes, Amazon Bedrock provides streaming APIs for model responses, including **ConverseStream**, **InvokeModelWithResponseStream**, and **RetrieveAndGenerateStream** [Chunk 1][Chunk 3]. You can check if a model supports streaming via the `responseStreamingSupported` field [Chunk 4].",
      "ground_truth_answer": "Yes, Amazon Bedrock supports response streaming through the InvokeModelWithResponseStream and ConverseStream API operations. The field 'responseStreamingSupported' in the API documentation indicates whether a specific model supports streaming.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.7688,
      "answer_correctness": 0.6981
    },
    {
      "question": "Can I directly apply a guardrail through an API call?",
      "category": "paraphrase",
      "predicted_answer": "Yes, you can directly apply a guardrail through the **ApplyGuardrail API** without invoking foundation models [Chunk 2].",
      "ground_truth_answer": "Yes, you can apply a guardrail directly through the ApplyGuardrail API operation, which evaluates content against your configured guardrail policies.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.662,
      "answer_correctness": 0.725
    },
    {
      "question": "Name at least 5 runtime invocation metrics Bedrock publishes (CloudWatch)",
      "category": "paraphrase",
      "predicted_answer": "1. Invocations [Chunk 1]\n2. InvocationLatency [Chunk 1]\n3. InvocationClientErrors [Chunk 1, 3]\n4. InvocationServerErrors [Chunk 3]\n5. InvocationThrottles [Chunk 3]",
      "ground_truth_answer": "Amazon Bedrock tracks Invocations, InvocationLatency, InvocationClientErrors, InvocationServerErrors, InvocationThrottles, InputTokenCount, OutputTokenCount, LegacyModelInvocations, and OutputImageCount.",
      "context_precision": 0.0,
      "context_recall": 0.5556,
      "faithfulness": 1.0,
      "answer_relevancy": 0.3756,
      "answer_correctness": 0.3
    },
    {
      "question": "In Amazon Bedrock inference, which service tier is used by default when the 'service_tier' parameter is missing?",
      "category": "factual",
      "predicted_answer": "The Standard tier is used by default when the \"service_tier\" parameter is missing, and you can explicitly set it to \"default\" to use the Standard tier [Chunk 1].",
      "ground_truth_answer": "By default, inference requests are routed to the Standard tier when the 'service_tier' parameter is missing.",
      "context_precision": 1.0,
      "context_recall": 1.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.75,
      "answer_correctness": 0.7081
    },
    {
      "question": "What is the default PostgreSQL version used internally by Bedrock?",
      "category": "no_answer",
      "predicted_answer": null,
      "ground_truth_answer": null,
      "context_precision": 0.0,
      "context_recall": 0.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.0,
      "answer_correctness": 1.0
    },
    {
      "question": "Which color theme does the AWS Bedrock console use by default?",
      "category": "no_answer",
      "predicted_answer": null,
      "ground_truth_answer": null,
      "context_precision": 0.0,
      "context_recall": 0.0,
      "faithfulness": 0.0,
      "answer_relevancy": 0.0,
      "answer_correctness": 1.0
    },
    {
      "question": "What salary does an AWS Bedrock product manager earn?",
      "category": "no_answer",
      "predicted_answer": null,
      "ground_truth_answer": null,
      "context_precision": 0.0,
      "context_recall": 0.0,
      "faithfulness": 1.0,
      "answer_relevancy": 0.0,
      "answer_correctness": 1.0
    },
    {
      "question": "What was the weather in Seattle when Bedrock launched?",
      "category": "no_answer",
      "predicted_answer": null,
      "ground_truth_answer": null,
      "context_precision": 0.0,
      "context_recall": 1.0,
      "faithfulness": 0.0,
      "answer_relevancy": 0.0,
      "answer_correctness": 1.0
    }
  ]
}