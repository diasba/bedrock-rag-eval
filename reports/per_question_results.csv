question,category,predicted_answer,ground_truth_answer,context_precision,context_recall,faithfulness,answer_relevancy,answer_correctness
What is Amazon Bedrock?,factual,"Amazon Bedrock is a fully managed service that provides secure, enterprise-grade access to high-performing foundation models from leading AI companies, enabling you to build and scale generative AI applications [Chunk 1].",Amazon Bedrock is a fully managed service that makes foundation models from leading AI companies available through a unified API.,1.0,1.0,1.0,1.0,0.7354
Do you need model access permissions before using some Bedrock models?,factual,"Yes, you need to request or modify model access permissions for Amazon Bedrock foundation models before using them, except in cases where access is enabled by default with the correct AWS Marketplace permissions in commercial AWS regions [Chunk 1][Chunk 2]. Specifically, you must configure access via the console or SDK/CLI for third-party models [Chunk 1][Chunk 2].","Yes, you need to request and be granted model access before you can use foundation models in Amazon Bedrock.",0.8056,1.0,1.0,0.5906,0.6984
Where can you find supported models for Bedrock?,factual,"You can find the list of supported foundation models for Amazon Bedrock in the ""Supported foundation models in Amazon Bedrock"" table in the Amazon Bedrock User Guide [Chunk 1]. Additionally, for embedding models used in knowledge bases, refer to ""Supported models and Regions for Amazon Bedrock knowledge bases"" [Chunk 2][Chunk 3].",You can find the list of supported models in the Amazon Bedrock documentation under the supported models page.,1.0,1.0,1.0,0.8235,0.6446
What is a Bedrock Knowledge Base used for?,factual,"A Bedrock Knowledge Base is used to integrate proprietary information into generative-AI applications by retrieving relevant data from connected data sources to improve the relevancy and accuracy of generated responses. It supports the RAG (Retrieval-Augmented Generation) process, enabling applications to answer queries using direct quotations or natural responses based on retrieved context [Chunk 1][Chunk 2][Chunk 4].",A Bedrock Knowledge Base is used to give foundation models contextual information from your private data sources for Retrieval Augmented Generation (RAG).,0.9167,1.0,1.0,0.9444,0.6754
What does chunking do in a knowledge base pipeline?,factual,"Chunking in a knowledge base pipeline splits documents into smaller, manageable subdivisions (chunks) based on parameters like token count, enabling efficient data retrieval by converting these chunks into embeddings for vector indexing while maintaining a link to the original document [Chunk 1][Chunk 4]. This process helps control the amount of text inserted into the `$search_results$` placeholder in prompt templates [Chunk 2][Chunk 3].",Chunking splits documents into smaller segments so they can be efficiently embedded and retrieved during a query.,0.9167,1.0,1.0,0.9767,0.6347
What is the purpose of RetrieveAndGenerate?,factual,"The purpose of `RetrieveAndGenerate` is to perform the entire RAG (Retrieval-Augmented Generation) process by:
1. Converting natural language queries into structured queries (if connected to a structured data store) using `GenerateQuery`,
2. Retrieving relevant document chunks from the knowledge base, and
3. Generating a response from the LLM with citations to the original source data [Chunk 1][Chunk 3]. It may also use a reranking model to improve document relevance [Chunk 2].","RetrieveAndGenerate queries a knowledge base, retrieves relevant results, and generates a response by augmenting the foundation model prompt with the retrieved information.",0.8333,1.0,1.0,0.8131,0.5908
"What is enabled by default with the correct AWS Marketplace permissions, and which table shows model support by AWS Region?",multi_hop,"Access to all Amazon Bedrock foundation models is enabled by default with the correct AWS Marketplace permissions [Chunk 1]. The table showing inference profile support by AWS Region is found in the ""Supported Regions and models for inference profiles"" section [Chunk 2].",Access to all Amazon Bedrock foundation models is enabled by default with the correct AWS Marketplace permissions. Model support by AWS Region is shown in the model support by AWS Region table.,0.0,0.5,1.0,0.4708,0.7667
"In fixed-size chunking, what two settings define chunk size and overlap, and in retrievalConfiguration.vectorSearchConfiguration which field sets the maximum number of results?",multi_hop,"In fixed-size chunking, the two settings are the **number of tokens per chunk** and the **overlap percentage** [Chunk 2]. In `retrievalConfiguration.vectorSearchConfiguration`, the **`numberOfResults`** field sets the maximum number of results [Chunk 1].","In fixed-size chunking, the two settings are the number of tokens per chunk and the overlap percentage. In retrievalConfiguration.vectorSearchConfiguration, the field that sets the maximum number of results is numberOfResults.",0.5,1.0,1.0,0.9112,0.8417
"In Amazon Bedrock, which feature searches your data to answer a query, and which feature evaluates both user inputs and model responses?",multi_hop,The feature that searches your data to answer a query is **Amazon Bedrock Knowledge Bases** [Chunk 1]. The feature that evaluates both retrieval effectiveness from data sources and the quality of generated responses is **Amazon Bedrock RAG evaluations** [Chunk 4].,"When a query is made, a knowledge base searches your data to find relevant information to answer the query. Amazon Bedrock Guardrails evaluates both user inputs and model responses.",1.0,0.5,1.0,0.7831,0.3457
"For Amazon Bedrock inference, which endpoint is used for InvokeModel calls, and what controls model inference usage?",multi_hop,"For Amazon Bedrock inference, the **`bedrock-runtime.{region}.amazonaws.com`** endpoint is used for `InvokeModel` calls [Chunk 1]. Model inference usage is controlled through **Service Control Policies (SCP) or IAM policies**, which initially block access until you agree to the EULA terms [Chunk 3].",InvokeModel calls use the bedrock-runtime.{region}.amazonaws.com endpoint. Model inference in Amazon Bedrock is controlled by quotas on token usage.,1.0,0.5,1.0,0.7908,0.5991
Can Bedrock KB do RAG-style retrieval before generation?,paraphrase,"Yes, Amazon Bedrock Knowledge Bases perform RAG-style retrieval by fetching relevant information from data sources before generating responses [Chunk 1][Chunk 4]. This retrieved information is then used to improve the accuracy and relevance of the generated output.","Yes, Bedrock Knowledge Bases support RAG-style retrieval before generation through the RetrieveAndGenerate API, which first queries the knowledge base for relevant results and then uses them to augment the prompt for the foundation model.",0.75,0.0,1.0,0.6387,0.6938
How do I check token count before sending a prompt?,paraphrase,"Use the `CountTokens` API operation, which accepts the same input formats as `InvokeModel` or `Converse` and returns the token count that would be used for the given prompt [Chunk 1][Chunk 2].",You can use the CountTokens API operation to count the number of tokens in a prompt before sending it to a model.,1.0,1.0,1.0,0.6503,0.6532
Is there an API for streaming model responses?,paraphrase,"Yes, Amazon Bedrock provides APIs for streaming model responses:
- **ConverseStream** (works with all models supporting messages) [Chunk 1][Chunk 2]
- **InvokeModelWithResponseStream** [Chunk 1]
- **RetrieveAndGenerateStream** (for knowledge base queries) [Chunk 3].","Yes, Amazon Bedrock supports response streaming through the InvokeModelWithResponseStream and ConverseStream API operations. The field 'responseStreamingSupported' in the API documentation indicates whether a specific model supports streaming.",1.0,1.0,1.0,0.7675,0.649
Can I directly apply a guardrail through an API call?,paraphrase,"Yes, you can directly apply a guardrail through the **ApplyGuardrail API** without invoking foundation models [Chunk 1][Chunk 2]. Additionally, you can use guardrails during inference by specifying the guardrail ID and version in supported APIs like **Converse** or **RetrieveAndGenerate** [Chunk 2][Chunk 4].","Yes, you can apply a guardrail directly through the ApplyGuardrail API operation, which evaluates content against your configured guardrail policies.",1.0,1.0,1.0,0.661,0.6053
Name at least 5 runtime invocation metrics Bedrock publishes (CloudWatch),paraphrase,"1. Invocations [Chunk 1]
2. InvocationLatency [Chunk 1]
3. InvocationClientErrors [Chunk 1, Chunk 3]
4. InvocationServerErrors [Chunk 3]
5. InvocationThrottles [Chunk 3]","Amazon Bedrock tracks Invocations, InvocationLatency, InvocationClientErrors, InvocationServerErrors, InvocationThrottles, InputTokenCount, OutputTokenCount, LegacyModelInvocations, and OutputImageCount.",0.0,0.5556,1.0,0.4427,0.3
"In Amazon Bedrock inference, which service tier is used by default when the 'service_tier' parameter is missing?",factual,"When the ""service_tier"" parameter is missing in an Amazon Bedrock inference request, the **Standard tier** (also referred to as ""default"") is used by default [Chunk 1][Chunk 2].","By default, inference requests are routed to the Standard tier when the 'service_tier' parameter is missing.",0.5,1.0,1.0,0.9446,0.6875
What is the default PostgreSQL version used internally by Bedrock?,no_answer,,,0.0,0.0,0.0,0.0,1.0
Which color theme does the AWS Bedrock console use by default?,no_answer,,,0.0,0.0,0.0,0.0,1.0
What salary does an AWS Bedrock product manager earn?,no_answer,,,0.0,1.0,1.0,0.0,1.0
What was the weather in Seattle when Bedrock launched?,no_answer,,,0.0,0.0,0.0,0.0,1.0
